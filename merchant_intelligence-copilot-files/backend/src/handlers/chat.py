"""
Chat Handler - LLM-powered conversational interface
Uses Bedrock Nova for intelligent responses based on insights data
"""

import json
import logging
from typing import Dict, Any
from common.responses import ok, bad
from common.config import BEDROCK_MODEL_FAST
from common.bedrock_nova import nova_converse
from common.validators import validate_prompt_injection

logger = logging.getLogger()
logger.setLevel(logging.INFO)


def lambda_handler(event: Dict[str, Any], context: Any) -> Dict[str, Any]:
    """
    Handle chat requests with LLM-powered responses.
    
    Expected request body:
    {
        "message": "Which products should I order?",
        "language": "en",  # Optional: "en", "hi", "mr"
        "insights": {...}  # Optional: current insights data for context
    }
    """
    try:
        # Parse request body
        body = json.loads(event.get('body', '{}'))
        message = body.get('message', '').strip()
        language = body.get('language', 'en')
        insights = body.get('insights')
        
        if not message:
            return bad("Message is required")
        
        # Validate for prompt injection
        if not validate_prompt_injection(message):
            return bad("Invalid message content")
        
        logger.info(f"Chat request - Message: {message[:100]}, Language: {language}")
        
        # Log insights data structure for debugging
        if insights:
            if 'insights' in insights and isinstance(insights['insights'], dict):
                products_count = len(insights['insights'].get('products', []))
                logger.info(f"Insights structure: nested, products count: {products_count}")
            elif 'products' in insights:
                products_count = len(insights.get('products', []))
                logger.info(f"Insights structure: flat, products count: {products_count}")
            else:
                logger.warning(f"Insights structure unknown: {list(insights.keys())}")
        else:
            logger.info("No insights data provided")
        
        # Generate LLM response with context
        response_text = generate_llm_response(message, language, insights)
        
        return ok({
            'response': response_text,
            'language': language,
            'disclaimer': 'AI-assisted insights. Review with your business knowledge.'
        })
        
    except Exception as e:
        logger.error(f"Error in chat handler: {str(e)}", exc_info=True)
        return bad(f"Error processing chat request: {str(e)}")


def generate_llm_response(message: str, language: str, insights: Dict = None) -> str:
    """
    Generate LLM-powered responses with business context.
    """
    import time
    start_time = time.time()
    
    message_lower = message.lower()
    logger.info(f"Processing message: '{message_lower}'")
    
    # Check if insights data is available and extract products
    products = []
    if insights:
        # Handle nested structure: insights.insights.products or insights.products
        if 'insights' in insights and isinstance(insights['insights'], dict):
            products = insights['insights'].get('products', [])
        elif 'products' in insights:
            products = insights.get('products', [])
    
    if not products:
        logger.info(f"No products found, using LLM for general business advice (took {time.time() - start_time:.3f}s)")
        return get_no_data_response(language, message)
    
    logger.info(f"Found {len(products)} products")
    
    high_urgency = [p for p in products if p.get('reorder', {}).get('urgency') == 'high']
    medium_urgency = [p for p in products if p.get('reorder', {}).get('urgency') == 'medium']
    anomalies = [p for p in products if p.get('anomalies') and len(p['anomalies']) > 0]
    low_confidence = [p for p in products if p.get('confidence_score', 100) < 60]
    
    # Use LLM for all queries with business context
    logger.info(f"Using LLM for response (took {time.time() - start_time:.3f}s so far)")
    return generate_llm_complex_response(message, language, products, high_urgency, anomalies)


def generate_reorder_response(high_urgency: list, medium_urgency: list, language: str) -> str:
    """Fast response for reorder questions"""
    if language == 'en':
        if not high_urgency and not medium_urgency:
            return "тЬЕ Good news! All products have sufficient stock levels. No urgent reorders needed right now."
        
        response = "ЁЯУж Reorder Recommendations:\n\n"
        if high_urgency:
            response += "ЁЯФ┤ HIGH PRIORITY (Order immediately):\n"
            for p in high_urgency[:5]:
                response += f"тАв {p['product_name']} - Order {p['reorder']['quantity']} units\n"
        if medium_urgency:
            response += f"\nЁЯЯб MEDIUM PRIORITY (Order within 3-5 days):\n"
            for p in medium_urgency[:3]:
                response += f"тАв {p['product_name']} - Order {p['reorder']['quantity']} units\n"
        return response
    
    elif language == 'hi':
        if not high_urgency and not medium_urgency:
            return "тЬЕ рдЕрдЪреНрдЫреА рдЦрдмрд░! рд╕рднреА рдЙрддреНрдкрд╛рджреЛрдВ рдореЗрдВ рдкрд░реНрдпрд╛рдкреНрдд рд╕реНрдЯреЙрдХ рд╣реИред рдЕрднреА рдХреЛрдИ рддрддреНрдХрд╛рд▓ рдкреБрдирдГ рдСрд░реНрдбрд░ рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛ рдирд╣реАрдВред"
        
        response = "ЁЯУж рдкреБрдирдГ рдСрд░реНрдбрд░ рд╕рд┐рдлрд╛рд░рд┐рд╢реЗрдВ:\n\n"
        if high_urgency:
            response += "ЁЯФ┤ рдЙрдЪреНрдЪ рдкреНрд░рд╛рдердорд┐рдХрддрд╛ (рддреБрд░рдВрдд рдСрд░реНрдбрд░ рдХрд░реЗрдВ):\n"
            for p in high_urgency[:5]:
                response += f"тАв {p['product_name']} - {p['reorder']['quantity']} рдпреВрдирд┐рдЯ рдСрд░реНрдбрд░ рдХрд░реЗрдВ\n"
        if medium_urgency:
            response += f"\nЁЯЯб рдордзреНрдпрдо рдкреНрд░рд╛рдердорд┐рдХрддрд╛ (3-5 рджрд┐рдиреЛрдВ рдореЗрдВ рдСрд░реНрдбрд░ рдХрд░реЗрдВ):\n"
            for p in medium_urgency[:3]:
                response += f"тАв {p['product_name']} - {p['reorder']['quantity']} рдпреВрдирд┐рдЯ рдСрд░реНрдбрд░ рдХрд░реЗрдВ\n"
        return response
    
    else:  # Marathi
        if not high_urgency and not medium_urgency:
            return "тЬЕ рдЪрд╛рдВрдЧрд▓реА рдмрд╛рддрдореА! рд╕рд░реНрд╡ рдЙрддреНрдкрд╛рджрдирд╛рдВрдордзреНрдпреЗ рдкреБрд░реЗрд╕рд╛ рд╕реНрдЯреЙрдХ рдЖрд╣реЗред рдЖрддреНрддрд╛ рдХреЛрдгрддреНрдпрд╛рд╣реА рддрд╛рддрдбреАрдЪреНрдпрд╛ рдкреБрдиреНрд╣рд╛ рдСрд░реНрдбрд░рдЪреА рдЧрд░рдЬ рдирд╛рд╣реА."
        
        response = "ЁЯУж рдкреБрдиреНрд╣рд╛ рдСрд░реНрдбрд░ рд╢рд┐рдлрд╛рд░рд╕реА:\n\n"
        if high_urgency:
            response += "ЁЯФ┤ рдЙрдЪреНрдЪ рдкреНрд░рд╛рдзрд╛рдиреНрдп (рд▓рдЧреЗрдЪ рдСрд░реНрдбрд░ рдХрд░рд╛):\n"
            for p in high_urgency[:5]:
                response += f"тАв {p['product_name']} - {p['reorder']['quantity']} рдпреБрдирд┐рдЯ рдСрд░реНрдбрд░ рдХрд░рд╛\n"
        if medium_urgency:
            response += f"\nЁЯЯб рдордзреНрдпрдо рдкреНрд░рд╛рдзрд╛рдиреНрдп (3-5 рджрд┐рд╡рд╕рд╛рдВрдд рдСрд░реНрдбрд░ рдХрд░рд╛):\n"
            for p in medium_urgency[:3]:
                response += f"тАв {p['product_name']} - {p['reorder']['quantity']} рдпреБрдирд┐рдЯ рдСрд░реНрдбрд░ рдХрд░рд╛\n"
        return response


def generate_top_products_response(products: list, language: str) -> str:
    """Fast response for top products questions"""
    sorted_products = sorted(products, key=lambda p: sum([f.get('yhat', 0) for f in p.get('forecast', [])]), reverse=True)[:5]
    
    if language == 'en':
        response = "ЁЯФЭ Top Selling Products:\n\n"
        for i, p in enumerate(sorted_products, 1):
            forecast_sum = sum([f.get('yhat', 0) for f in p.get('forecast', [])])
            response += f"{i}. {p['product_name']} - {forecast_sum:.0f} units (7-day forecast)\n"
        response += "\nЁЯТб Tip: Keep higher stock levels for these products to avoid stockouts."
        return response
    
    elif language == 'hi':
        response = "ЁЯФЭ рд╕рдмрд╕реЗ рдЬрд╝реНрдпрд╛рджрд╛ рдмрд┐рдХрдиреЗ рд╡рд╛рд▓реЗ рдЙрддреНрдкрд╛рдж:\n\n"
        for i, p in enumerate(sorted_products, 1):
            forecast_sum = sum([f.get('yhat', 0) for f in p.get('forecast', [])])
            response += f"{i}. {p['product_name']} - {forecast_sum:.0f} рдпреВрдирд┐рдЯ (7-рджрд┐рди рдХрд╛ рдкреВрд░реНрд╡рд╛рдиреБрдорд╛рди)\n"
        response += "\nЁЯТб рд╕реБрдЭрд╛рд╡: рд╕реНрдЯреЙрдХрдЖрдЙрдЯ рд╕реЗ рдмрдЪрдиреЗ рдХреЗ рд▓рд┐рдП рдЗрди рдЙрддреНрдкрд╛рджреЛрдВ рдХрд╛ рдЕрдзрд┐рдХ рд╕реНрдЯреЙрдХ рд░рдЦреЗрдВред"
        return response
    
    else:  # Marathi
        response = "ЁЯФЭ рд╕рд░реНрд╡рд╛рдзрд┐рдХ рд╡рд┐рдХреНрд░реА рд╣реЛрдгрд╛рд░реА рдЙрддреНрдкрд╛рджрдиреЗ:\n\n"
        for i, p in enumerate(sorted_products, 1):
            forecast_sum = sum([f.get('yhat', 0) for f in p.get('forecast', [])])
            response += f"{i}. {p['product_name']} - {forecast_sum:.0f} рдпреБрдирд┐рдЯ (7-рджрд┐рд╡рд╕рд╛рдВрдЪрд╛ рдЕрдВрджрд╛рдЬ)\n"
        response += "\nЁЯТб рдЯреАрдк: рд╕реНрдЯреЙрдХрдЖрдЙрдЯ рдЯрд╛рд│рдгреНрдпрд╛рд╕рд╛рдареА рдпрд╛ рдЙрддреНрдкрд╛рджрдирд╛рдВрдЪрд╛ рдЬрд╛рд╕реНрдд рд╕реНрдЯреЙрдХ рдареЗрд╡рд╛."
        return response


def generate_alerts_response(anomalies: list, language: str) -> str:
    """Fast response for alerts/anomalies questions"""
    if language == 'en':
        if not anomalies:
            return "тЬЕ No unusual patterns detected. All products showing normal demand trends."
        
        response = "тЪая╕П Demand Alerts:\n\n"
        for p in anomalies[:5]:
            response += f"тАв {p['product_name']}:\n"
            for anomaly in p['anomalies'][:2]:
                response += f"  - {anomaly}\n"
        response += "\nЁЯТб Review these products and adjust inventory/pricing accordingly."
        return response
    
    elif language == 'hi':
        if not anomalies:
            return "тЬЕ рдХреЛрдИ рдЕрд╕рд╛рдорд╛рдиреНрдп рдкреИрдЯрд░реНрди рдирд╣реАрдВ рдорд┐рд▓рд╛ред рд╕рднреА рдЙрддреНрдкрд╛рдж рд╕рд╛рдорд╛рдиреНрдп рдорд╛рдВрдЧ рд░реБрдЭрд╛рди рджрд┐рдЦрд╛ рд░рд╣реЗ рд╣реИрдВред"
        
        response = "тЪая╕П рдорд╛рдВрдЧ рдЕрд▓рд░реНрдЯ:\n\n"
        for p in anomalies[:5]:
            response += f"тАв {p['product_name']}:\n"
            for anomaly in p['anomalies'][:2]:
                response += f"  - {anomaly}\n"
        response += "\nЁЯТб рдЗрди рдЙрддреНрдкрд╛рджреЛрдВ рдХреА рд╕рдореАрдХреНрд╖рд╛ рдХрд░реЗрдВ рдФрд░ рддрджрдиреБрд╕рд╛рд░ рдЗрдиреНрд╡реЗрдВрдЯрд░реА/рдореВрд▓реНрдп рдирд┐рд░реНрдзрд╛рд░рдг рд╕рдорд╛рдпреЛрдЬрд┐рдд рдХрд░реЗрдВред"
        return response
    
    else:  # Marathi
        if not anomalies:
            return "тЬЕ рдХреЛрдгрддреЗрд╣реА рдЕрд╕рд╛рдорд╛рдиреНрдп рдкреЕрдЯрд░реНрди рдЖрдврд│рд▓реЗ рдирд╛рд╣реАрдд. рд╕рд░реНрд╡ рдЙрддреНрдкрд╛рджрдиреЗ рд╕рд╛рдорд╛рдиреНрдп рдорд╛рдЧрдгреА рдЯреНрд░реЗрдВрдб рджрд░реНрд╢рд╡рдд рдЖрд╣реЗрдд."
        
        response = "тЪая╕П рдорд╛рдЧрдгреА рдЕрд▓рд░реНрдЯ:\n\n"
        for p in anomalies[:5]:
            response += f"тАв {p['product_name']}:\n"
            for anomaly in p['anomalies'][:2]:
                response += f"  - {anomaly}\n"
        response += "\nЁЯТб рдпрд╛ рдЙрддреНрдкрд╛рджрдирд╛рдВрдЪреЗ рдкреБрдирд░рд╛рд╡рд▓реЛрдХрди рдХрд░рд╛ рдЖрдгрд┐ рддреНрдпрд╛рдиреБрд╕рд╛рд░ рдЗрдиреНрд╡реНрд╣реЗрдВрдЯрд░реА/рдХрд┐рдВрдордд рд╕рдорд╛рдпреЛрдЬрд┐рдд рдХрд░рд╛."
        return response


def generate_forecast_response(products: list, language: str) -> str:
    """Fast response for forecast questions"""
    total_forecast = sum([sum([f.get('yhat', 0) for f in p.get('forecast', [])]) for p in products])
    avg_confidence = sum([p.get('confidence_score', 0) for p in products]) / len(products) if products else 0
    
    if language == 'en':
        response = f"ЁЯУК 7-Day Forecast Summary:\n\n"
        response += f"тАв Total expected sales: {total_forecast:.0f} units\n"
        response += f"тАв Average confidence: {avg_confidence:.0f}%\n"
        response += f"тАв Products analyzed: {len(products)}\n\n"
        response += "Top 3 products by forecast:\n"
        sorted_products = sorted(products, key=lambda p: sum([f.get('yhat', 0) for f in p.get('forecast', [])]), reverse=True)[:3]
        for i, p in enumerate(sorted_products, 1):
            forecast_sum = sum([f.get('yhat', 0) for f in p.get('forecast', [])])
            response += f"{i}. {p['product_name']} - {forecast_sum:.0f} units\n"
        return response
    
    elif language == 'hi':
        response = f"ЁЯУК 7-рджрд┐рди рдХрд╛ рдкреВрд░реНрд╡рд╛рдиреБрдорд╛рди рд╕рд╛рд░рд╛рдВрд╢:\n\n"
        response += f"тАв рдХреБрд▓ рдЕрдкреЗрдХреНрд╖рд┐рдд рдмрд┐рдХреНрд░реА: {total_forecast:.0f} рдпреВрдирд┐рдЯ\n"
        response += f"тАв рдФрд╕рдд рд╡рд┐рд╢реНрд╡рд╛рд╕: {avg_confidence:.0f}%\n"
        response += f"тАв рд╡рд┐рд╢реНрд▓реЗрд╖рд┐рдд рдЙрддреНрдкрд╛рдж: {len(products)}\n\n"
        response += "рдкреВрд░реНрд╡рд╛рдиреБрдорд╛рди рдХреЗ рдЕрдиреБрд╕рд╛рд░ рд╢реАрд░реНрд╖ 3 рдЙрддреНрдкрд╛рдж:\n"
        sorted_products = sorted(products, key=lambda p: sum([f.get('yhat', 0) for f in p.get('forecast', [])]), reverse=True)[:3]
        for i, p in enumerate(sorted_products, 1):
            forecast_sum = sum([f.get('yhat', 0) for f in p.get('forecast', [])])
            response += f"{i}. {p['product_name']} - {forecast_sum:.0f} рдпреВрдирд┐рдЯ\n"
        return response
    
    else:  # Marathi
        response = f"ЁЯУК 7-рджрд┐рд╡рд╕рд╛рдВрдЪрд╛ рдЕрдВрджрд╛рдЬ рд╕рд╛рд░рд╛рдВрд╢:\n\n"
        response += f"тАв рдПрдХреВрдг рдЕрдкреЗрдХреНрд╖рд┐рдд рд╡рд┐рдХреНрд░реА: {total_forecast:.0f} рдпреБрдирд┐рдЯ\n"
        response += f"тАв рд╕рд░рд╛рд╕рд░реА рдЖрддреНрдорд╡рд┐рд╢реНрд╡рд╛рд╕: {avg_confidence:.0f}%\n"
        response += f"тАв рд╡рд┐рд╢реНрд▓реЗрд╖рд┐рдд рдЙрддреНрдкрд╛рджрдиреЗ: {len(products)}\n\n"
        response += "рдЕрдВрджрд╛рдЬрд╛рдиреБрд╕рд╛рд░ рд╢реАрд░реНрд╖ 3 рдЙрддреНрдкрд╛рджрдиреЗ:\n"
        sorted_products = sorted(products, key=lambda p: sum([f.get('yhat', 0) for f in p.get('forecast', [])]), reverse=True)[:3]
        for i, p in enumerate(sorted_products, 1):
            forecast_sum = sum([f.get('yhat', 0) for f in p.get('forecast', [])])
            response += f"{i}. {p['product_name']} - {forecast_sum:.0f} рдпреБрдирд┐рдЯ\n"
        return response


def generate_confidence_response(low_confidence: list, all_products: list, language: str) -> str:
    """Fast response for confidence/accuracy questions"""
    avg_confidence = sum([p.get('confidence_score', 0) for p in all_products]) / len(all_products) if all_products else 0
    
    if language == 'en':
        response = f"ЁЯУИ Forecast Confidence Report:\n\n"
        response += f"тАв Average confidence: {avg_confidence:.0f}%\n"
        response += f"тАв Products analyzed: {len(all_products)}\n"
        response += f"тАв Low confidence items: {len(low_confidence)}\n\n"
        
        if low_confidence:
            response += "тЪая╕П Products with low confidence (<60%):\n"
            for p in low_confidence[:3]:
                response += f"тАв {p['product_name']} - {p['confidence_score']:.0f}%\n"
            response += "\nЁЯТб Low confidence may indicate insufficient data or irregular patterns."
        else:
            response += "тЬЕ All forecasts have good confidence levels!"
        return response
    
    elif language == 'hi':
        response = f"ЁЯУИ рдкреВрд░реНрд╡рд╛рдиреБрдорд╛рди рд╡рд┐рд╢реНрд╡рд╛рд╕ рд░рд┐рдкреЛрд░реНрдЯ:\n\n"
        response += f"тАв рдФрд╕рдд рд╡рд┐рд╢реНрд╡рд╛рд╕: {avg_confidence:.0f}%\n"
        response += f"тАв рд╡рд┐рд╢реНрд▓реЗрд╖рд┐рдд рдЙрддреНрдкрд╛рдж: {len(all_products)}\n"
        response += f"тАв рдХрдо рд╡рд┐рд╢реНрд╡рд╛рд╕ рд╡рд╛рд▓реЗ рдЖрдЗрдЯрдо: {len(low_confidence)}\n\n"
        
        if low_confidence:
            response += "тЪая╕П рдХрдо рд╡рд┐рд╢реНрд╡рд╛рд╕ рд╡рд╛рд▓реЗ рдЙрддреНрдкрд╛рдж (<60%):\n"
            for p in low_confidence[:3]:
                response += f"тАв {p['product_name']} - {p['confidence_score']:.0f}%\n"
            response += "\nЁЯТб рдХрдо рд╡рд┐рд╢реНрд╡рд╛рд╕ рдЕрдкрд░реНрдпрд╛рдкреНрдд рдбреЗрдЯрд╛ рдпрд╛ рдЕрдирд┐рдпрдорд┐рдд рдкреИрдЯрд░реНрди рдХрд╛ рд╕рдВрдХреЗрдд рд╣реЛ рд╕рдХрддрд╛ рд╣реИред"
        else:
            response += "тЬЕ рд╕рднреА рдкреВрд░реНрд╡рд╛рдиреБрдорд╛рдиреЛрдВ рдореЗрдВ рдЕрдЪреНрдЫрд╛ рд╡рд┐рд╢реНрд╡рд╛рд╕ рд╕реНрддрд░ рд╣реИ!"
        return response
    
    else:  # Marathi
        response = f"ЁЯУИ рдЕрдВрджрд╛рдЬ рдЖрддреНрдорд╡рд┐рд╢реНрд╡рд╛рд╕ рдЕрд╣рд╡рд╛рд▓:\n\n"
        response += f"тАв рд╕рд░рд╛рд╕рд░реА рдЖрддреНрдорд╡рд┐рд╢реНрд╡рд╛рд╕: {avg_confidence:.0f}%\n"
        response += f"тАв рд╡рд┐рд╢реНрд▓реЗрд╖рд┐рдд рдЙрддреНрдкрд╛рджрдиреЗ: {len(all_products)}\n"
        response += f"тАв рдХрдореА рдЖрддреНрдорд╡рд┐рд╢реНрд╡рд╛рд╕ рдЕрд╕рд▓реЗрд▓реЗ рдЖрдпрдЯрдо: {len(low_confidence)}\n\n"
        
        if low_confidence:
            response += "тЪая╕П рдХрдореА рдЖрддреНрдорд╡рд┐рд╢реНрд╡рд╛рд╕ рдЕрд╕рд▓реЗрд▓реА рдЙрддреНрдкрд╛рджрдиреЗ (<60%):\n"
            for p in low_confidence[:3]:
                response += f"тАв {p['product_name']} - {p['confidence_score']:.0f}%\n"
            response += "\nЁЯТб рдХрдореА рдЖрддреНрдорд╡рд┐рд╢реНрд╡рд╛рд╕ рдЕрдкреБрд░рд╛ рдбреЗрдЯрд╛ рдХрд┐рдВрд╡рд╛ рдЕрдирд┐рдпрдорд┐рдд рдкреЕрдЯрд░реНрдирдЪреЗ рд╕рдВрдХреЗрдд рдЕрд╕реВ рд╢рдХрддреЗ."
        else:
            response += "тЬЕ рд╕рд░реНрд╡ рдЕрдВрджрд╛рдЬрд╛рдВрдордзреНрдпреЗ рдЪрд╛рдВрдЧрд▓рд╛ рдЖрддреНрдорд╡рд┐рд╢реНрд╡рд╛рд╕ рдкрд╛рддрд│реА рдЖрд╣реЗ!"
        return response


def generate_llm_complex_response(message: str, language: str, products: list, high_urgency: list, anomalies: list) -> str:
    """Use LLM with rich business context for intelligent responses"""
    
    logger.info("Generating LLM response with business context")
    
    lang_instruction = {
        'en': 'Respond in English',
        'hi': 'Respond in Hindi (рд╣рд┐рдВрджреА)',
        'mr': 'Respond in Marathi (рдорд░рд╛рдареА)'
    }.get(language, 'Respond in English')
    
    # Build rich context with product details
    top_products = sorted(products, key=lambda p: sum([f.get('yhat', 0) for f in p.get('forecast', [])]), reverse=True)[:5]
    
    context_parts = [
        f"Total products analyzed: {len(products)}",
        f"High urgency reorders: {len(high_urgency)}",
        f"Products with anomalies: {len(anomalies)}"
    ]
    
    if high_urgency:
        context_parts.append(f"\nHigh priority reorders: {', '.join([p['product_name'] + f' ({p['reorder']['quantity']} units)' for p in high_urgency[:3]])}")
    
    if anomalies:
        context_parts.append(f"\nProducts with alerts: {', '.join([p['product_name'] for p in anomalies[:3]])}")
    
    context_parts.append(f"\nTop selling products (7-day forecast): {', '.join([p['product_name'] + f' ({sum([f.get('yhat', 0) for f in p.get('forecast', [])]):.0f} units)' for p in top_products[:3]])}")
    
    context = "\n".join(context_parts)
    
    system = f"""You are an AI business advisor for Indian MSME merchants, specializing in inventory management and demand forecasting.

{lang_instruction}. Be conversational, helpful, and provide actionable insights.

Guidelines:
- Give specific, actionable recommendations
- Use emojis appropriately (ЁЯУж for orders, ЁЯФЭ for top products, тЪая╕П for alerts, ЁЯУК for forecasts)
- Keep responses concise but informative (3-5 sentences)
- Focus on business impact and next steps
- Use simple language suitable for small business owners"""
    
    user = f"""Business Context:
{context}

Merchant Question: {message}

Provide a helpful, actionable response based on the data."""
    
    try:
        response = nova_converse(BEDROCK_MODEL_FAST, system, user)
        return response
    except Exception as e:
        logger.error(f"LLM generation failed: {str(e)}")
        # Fallback to helpful menu
        if language == 'en':
            return f"""I can help you with:

ЁЯУж Reorder recommendations - Ask "Which products should I order?"
ЁЯФЭ Top products - Ask "What are my top selling products?"
тЪая╕П Alerts - Ask "Are there any demand spikes?"
ЁЯУК Forecasts - Ask "What's the forecast for next week?"

You have {len(products)} products analyzed with {len(high_urgency)} high priority reorders and {len(anomalies)} alerts."""
        
        elif language == 'hi':
            return f"""рдореИрдВ рдЖрдкрдХреА рдорджрдж рдХрд░ рд╕рдХрддрд╛ рд╣реВрдВ:

ЁЯУж рдкреБрдирдГ рдСрд░реНрдбрд░ рд╕рд┐рдлрд╛рд░рд┐рд╢реЗрдВ - рдкреВрдЫреЗрдВ "рдореБрдЭреЗ рдХреМрди рд╕реЗ рдЙрддреНрдкрд╛рдж рдСрд░реНрдбрд░ рдХрд░рдиреЗ рдЪрд╛рд╣рд┐рдП?"
ЁЯФЭ рд╢реАрд░реНрд╖ рдЙрддреНрдкрд╛рдж - рдкреВрдЫреЗрдВ "рдореЗрд░реЗ рд╕рдмрд╕реЗ рдЬрд╝реНрдпрд╛рджрд╛ рдмрд┐рдХрдиреЗ рд╡рд╛рд▓реЗ рдЙрддреНрдкрд╛рдж рдХреМрди рд╕реЗ рд╣реИрдВ?"
тЪая╕П рдЕрд▓рд░реНрдЯ - рдкреВрдЫреЗрдВ "рдХреНрдпрд╛ рдХреЛрдИ рдорд╛рдВрдЧ рдореЗрдВ рд╡реГрджреНрдзрд┐ рд╣реИ?"
ЁЯУК рдкреВрд░реНрд╡рд╛рдиреБрдорд╛рди - рдкреВрдЫреЗрдВ "рдЕрдЧрд▓реЗ рд╕рдкреНрддрд╛рд╣ рдХрд╛ рдкреВрд░реНрд╡рд╛рдиреБрдорд╛рди рдХреНрдпрд╛ рд╣реИ?"

рдЖрдкрдХреЗ рдкрд╛рд╕ {len(products)} рдЙрддреНрдкрд╛рдж рд╡рд┐рд╢реНрд▓реЗрд╖рд┐рдд рд╣реИрдВ рдЬрд┐рдирдореЗрдВ {len(high_urgency)} рдЙрдЪреНрдЪ рдкреНрд░рд╛рдердорд┐рдХрддрд╛ рдкреБрдирдГ рдСрд░реНрдбрд░ рдФрд░ {len(anomalies)} рдЕрд▓рд░реНрдЯ рд╣реИрдВред"""
        
        else:  # Marathi
            return f"""рдореА рддреБрдореНрд╣рд╛рд▓рд╛ рдорджрдд рдХрд░реВ рд╢рдХрддреЛ:

ЁЯУж рдкреБрдиреНрд╣рд╛ рдСрд░реНрдбрд░ рд╢рд┐рдлрд╛рд░рд╕реА - рд╡рд┐рдЪрд╛рд░рд╛ "рдорд▓рд╛ рдХреЛрдгрддреА рдЙрддреНрдкрд╛рджрдиреЗ рдорд╛рдЧрд╡рд╛рд╡реА?"
ЁЯФЭ рд╢реАрд░реНрд╖ рдЙрддреНрдкрд╛рджрдиреЗ - рд╡рд┐рдЪрд╛рд░рд╛ "рдорд╛рдЭреА рд╕рд░реНрд╡рд╛рдзрд┐рдХ рд╡рд┐рдХреНрд░реА рд╣реЛрдгрд╛рд░реА рдЙрддреНрдкрд╛рджрдиреЗ рдХреЛрдгрддреА рдЖрд╣реЗрдд?"
тЪая╕П рдЕрд▓рд░реНрдЯ - рд╡рд┐рдЪрд╛рд░рд╛ "рдорд╛рдЧрдгреАрдд рдХрд╛рд╣реА рд╡рд╛рдв рдЖрд╣реЗ рдХрд╛?"
ЁЯУК рдЕрдВрджрд╛рдЬ - рд╡рд┐рдЪрд╛рд░рд╛ "рдкреБрдвреАрд▓ рдЖрдард╡рдбреНрдпрд╛рдЪрд╛ рдЕрдВрджрд╛рдЬ рдХрд╛рдп рдЖрд╣реЗ?"

рддреБрдордЪреНрдпрд╛рдХрдбреЗ {len(products)} рдЙрддреНрдкрд╛рджрдиреЗ рд╡рд┐рд╢реНрд▓реЗрд╖рд┐рдд рдЖрд╣реЗрдд рдЬреНрдпрд╛рдд {len(high_urgency)} рдЙрдЪреНрдЪ рдкреНрд░рд╛рдзрд╛рдиреНрдп рдкреБрдиреНрд╣рд╛ рдСрд░реНрдбрд░ рдЖрдгрд┐ {len(anomalies)} рдЕрд▓рд░реНрдЯ рдЖрд╣реЗрддред"""


def get_no_data_response(language: str, message: str) -> str:
    """
    Response when no insights data is available.
    Uses LLM to answer general business questions.
    """
    logger.info("No insights data available, using LLM for general business advice")
    
    lang_instruction = {
        'en': 'Respond in English',
        'hi': 'Respond in Hindi (рд╣рд┐рдВрджреА)',
        'mr': 'Respond in Marathi (рдорд░рд╛рдареА)'
    }.get(language, 'Respond in English')
    
    system = f"""You are an AI business advisor for Indian MSME (Micro, Small, and Medium Enterprises) merchants.

{lang_instruction}. Be conversational, helpful, and provide practical business advice.

Guidelines:
- Provide general business advice for small merchants in India
- Focus on inventory management, sales strategies, customer service, and business growth
- Use simple language suitable for small business owners
- Keep responses concise (3-5 sentences)
- Use emojis appropriately to make responses friendly
- If asked about specific product data, remind them to upload their sales data for personalized insights

Topics you can help with:
- Inventory management best practices
- Pricing strategies
- Customer retention
- Business growth tips
- Marketing for small businesses
- Cash flow management
- Seasonal planning"""
    
    user = f"""The merchant hasn't uploaded their sales data yet, so I don't have specific product information.

Merchant Question: {message}

Provide helpful general business advice. If the question requires specific data analysis, politely suggest they upload their sales data."""
    
    try:
        response = nova_converse(BEDROCK_MODEL_FAST, system, user)
        
        # Add a gentle reminder about uploading data for personalized insights
        if language == 'en':
            response += "\n\nЁЯТб Tip: Upload your sales data to get personalized insights and forecasts for your specific products!"
        elif language == 'hi':
            response += "\n\nЁЯТб рд╕реБрдЭрд╛рд╡: рдЕрдкрдиреЗ рд╡рд┐рд╢рд┐рд╖реНрдЯ рдЙрддреНрдкрд╛рджреЛрдВ рдХреЗ рд▓рд┐рдП рд╡реНрдпрдХреНрддрд┐рдЧрдд рдЕрдВрддрд░реНрджреГрд╖реНрдЯрд┐ рдФрд░ рдкреВрд░реНрд╡рд╛рдиреБрдорд╛рди рдкреНрд░рд╛рдкреНрдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдЕрдкрдирд╛ рдмрд┐рдХреНрд░реА рдбреЗрдЯрд╛ рдЕрдкрд▓реЛрдб рдХрд░реЗрдВ!"
        else:  # Marathi
            response += "\n\nЁЯТб рдЯреАрдк: рддреБрдордЪреНрдпрд╛ рд╡рд┐рд╢рд┐рд╖реНрдЯ рдЙрддреНрдкрд╛рджрдирд╛рдВрд╕рд╛рдареА рд╡реИрдпрдХреНрддрд┐рдХ рдЕрдВрддрд░реНрджреГрд╖реНрдЯреА рдЖрдгрд┐ рдЕрдВрджрд╛рдЬ рдорд┐рд│рд╡рд┐рдгреНрдпрд╛рд╕рд╛рдареА рддреБрдордЪрд╛ рд╡рд┐рдХреНрд░реА рдбреЗрдЯрд╛ рдЕрдкрд▓реЛрдб рдХрд░рд╛!"
        
        return response
        
    except Exception as e:
        logger.error(f"LLM generation failed for general query: {str(e)}")
        # Fallback response
        if language == 'en':
            return """ЁЯСЛ Hello! I'm your AI business advisor for inventory management and demand forecasting.

ЁЯУК To get started, please upload your sales data (CSV format with date, product_name, quantity_sold, price, revenue columns).

I can help you with:
тАв Demand forecasting and inventory planning
тАв Reorder recommendations
тАв Sales trend analysis
тАв Price optimization suggestions

Once you upload your data, I'll provide personalized insights for your business!"""
        
        elif language == 'hi':
            return """ЁЯСЛ рдирдорд╕реНрддреЗ! рдореИрдВ рдЗрдиреНрд╡реЗрдВрдЯрд░реА рдкреНрд░рдмрдВрдзрди рдФрд░ рдорд╛рдВрдЧ рдкреВрд░реНрд╡рд╛рдиреБрдорд╛рди рдХреЗ рд▓рд┐рдП рдЖрдкрдХрд╛ AI рд╡реНрдпрд╡рд╕рд╛рдп рд╕рд▓рд╛рд╣рдХрд╛рд░ рд╣реВрдВред

ЁЯУК рд╢реБрд░реВ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП, рдХреГрдкрдпрд╛ рдЕрдкрдирд╛ рдмрд┐рдХреНрд░реА рдбреЗрдЯрд╛ рдЕрдкрд▓реЛрдб рдХрд░реЗрдВ (CSV рдкреНрд░рд╛рд░реВрдк рдореЗрдВ date, product_name, quantity_sold, price, revenue рдХреЙрд▓рдо рдХреЗ рд╕рд╛рде)ред

рдореИрдВ рдЖрдкрдХреА рдорджрдж рдХрд░ рд╕рдХрддрд╛ рд╣реВрдВ:
тАв рдорд╛рдВрдЧ рдкреВрд░реНрд╡рд╛рдиреБрдорд╛рди рдФрд░ рдЗрдиреНрд╡реЗрдВрдЯрд░реА рдпреЛрдЬрдирд╛
тАв рдкреБрдирдГ рдСрд░реНрдбрд░ рд╕рд┐рдлрд╛рд░рд┐рд╢реЗрдВ
тАв рдмрд┐рдХреНрд░реА рд░реБрдЭрд╛рди рд╡рд┐рд╢реНрд▓реЗрд╖рдг
тАв рдореВрд▓реНрдп рдЕрдиреБрдХреВрд▓рди рд╕реБрдЭрд╛рд╡

рдПрдХ рдмрд╛рд░ рдЬрдм рдЖрдк рдЕрдкрдирд╛ рдбреЗрдЯрд╛ рдЕрдкрд▓реЛрдб рдХрд░ рджреЗрдВрдЧреЗ, рддреЛ рдореИрдВ рдЖрдкрдХреЗ рд╡реНрдпрд╡рд╕рд╛рдп рдХреЗ рд▓рд┐рдП рд╡реНрдпрдХреНрддрд┐рдЧрдд рдЕрдВрддрд░реНрджреГрд╖реНрдЯрд┐ рдкреНрд░рджрд╛рди рдХрд░реВрдВрдЧрд╛!"""
        
        else:  # Marathi
            return """ЁЯСЛ рдирдорд╕реНрдХрд╛рд░! рдореА рдЗрдиреНрд╡реНрд╣реЗрдВрдЯрд░реА рд╡реНрдпрд╡рд╕реНрдерд╛рдкрди рдЖрдгрд┐ рдорд╛рдЧрдгреА рдЕрдВрджрд╛рдЬрд╛рд╕рд╛рдареА рддреБрдордЪрд╛ AI рд╡реНрдпрд╡рд╕рд╛рдп рд╕рд▓реНрд▓рд╛рдЧрд╛рд░ рдЖрд╣реЗред

ЁЯУК рд╕реБрд░реБрд╡рд╛рдд рдХрд░рдгреНрдпрд╛рд╕рд╛рдареА, рдХреГрдкрдпрд╛ рддреБрдордЪрд╛ рд╡рд┐рдХреНрд░реА рдбреЗрдЯрд╛ рдЕрдкрд▓реЛрдб рдХрд░рд╛ (CSV рд╕реНрд╡рд░реВрдкрд╛рдд date, product_name, quantity_sold, price, revenue рд╕реНрддрдВрднрд╛рдВрд╕рд╣)ред

рдореА рддреБрдореНрд╣рд╛рд▓рд╛ рдорджрдд рдХрд░реВ рд╢рдХрддреЛ:
тАв рдорд╛рдЧрдгреА рдЕрдВрджрд╛рдЬ рдЖрдгрд┐ рдЗрдиреНрд╡реНрд╣реЗрдВрдЯрд░реА рдирд┐рдпреЛрдЬрди
тАв рдкреБрдиреНрд╣рд╛ рдСрд░реНрдбрд░ рд╢рд┐рдлрд╛рд░рд╕реА
тАв рд╡рд┐рдХреНрд░реА рдЯреНрд░реЗрдВрдб рд╡рд┐рд╢реНрд▓реЗрд╖рдг
тАв рдХрд┐рдВрдордд рдСрдкреНрдЯрд┐рдорд╛рдпрдЭреЗрд╢рди рд╕реВрдЪрдирд╛

рдПрдХрджрд╛ рддреБрдореНрд╣реА рддреБрдордЪрд╛ рдбреЗрдЯрд╛ рдЕрдкрд▓реЛрдб рдХреЗрд▓реНрдпрд╛рд╡рд░, рдореА рддреБрдордЪреНрдпрд╛ рд╡реНрдпрд╡рд╕рд╛рдпрд╛рд╕рд╛рдареА рд╡реИрдпрдХреНрддрд┐рдХ рдЕрдВрддрд░реНрджреГрд╖реНрдЯреА рдкреНрд░рджрд╛рди рдХрд░реЗрди!"""
